---
title: "Bias and Error in Herbarium data"
author: "Devin Gamble"
date: "7/28/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo = FALSE, message = FALSE, warning = FALSE}
#Load Packages
library(car)
library(tidyverse)
library(here)
library(ggplot2)
library(corrplot)
library(visreg)
library(jtools)
library(interactions)
```

# Examining the effect of error distance and other potential biases in herbarium data  

## Objective: Deteremine how records' error distance and other collection information might bias pheno-climatic models in *N. menziesii*  

### Table of Contents    
- Error distance  
    - By Data subsets  
    - As a covariate   
- Georeferrencing  
- Collection Biases  

Note: Several code chunks copied over from `EDA2.Rmd` and refined.    

**TO DO**  
- Effects of error_dist & georef_by to *Anomalies*??  
- Add Analyses on potential biases  
- Standardize data and variables used  
- Explore more complex models?  
- Include *interactions*  
- Include *sample sizes*  

<br>  

#### Load Data  
```{r message = FALSE, warning = FALSE}
nemo_df2 <- read_csv(here::here("data_cleaning", "nemo_full_1901_2019.csv")) %>%  
  mutate(error_bin = as_factor(error_bin)) #Should this be ordered? #Combined specimen & climate data from 1901-2019
#1677 obs, 1251 columns

nemo_df1 <- read_csv(here::here("data_cleaning", "nemo_full_1861_2019.csv")) #Combined data for all years
#1764 obs, 1251 columns
```

Data subset by error distances/bins  
```{r message = FALSE, warning = FALSE}
nemo_all_errors <- nemo_df2 %>% 
  filter(!is.na(error_dist_m)) 
#1239 out of 1764 obs with error distance
#1166 after rm records before 1901

#0-5 km resolution
nemo_e0_5 <- nemo_all_errors %>% 
  filter(error_bin == "<2 km" | error_bin == "2-5 km") 

#0-4 km
nemo_e0_4 <-  nemo_all_errors %>% 
  filter(error_dist_m >= 0 & error_dist_m <= 4000) #Do Not include error_bin in models

#0-2 km
nemo_e2 <- nemo_all_errors %>% 
  filter(error_bin == "<2 km") 

```


## Effect of Error Distance on DOY ~ Climate models  

Measure the effect of error distance on pheno-climatic models'
- $R^2$ values  
- Parameter estimates  
- significance of climate variables in their effect on DOY  

For 100 year averages for MAT, MAP, Tmin_sp, Tmin_wt, PPT_sp, PPT_wt  

*Note*: Rationale for using nemo_df2: error distance estiamtes are likely more accurate  after 1900.  

<br>  


### Subsetting data by error bins

Only significant interactions are shown although interactions among climate variables were tested for each original model.  

```{r message = FALSE, warning = FALSE}
##
#MAT & MAP
##
M100Y_lm1 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = nemo_df2)

er_an0 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = nemo_all_errors)
er_an1 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = nemo_e0_5)
er_an2 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = nemo_e2)

plot_summs(M100Y_lm1, er_an0, er_an1, er_an2, model.names = c("Original", "all errors", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()
#scale = TRUE refits model to mean-center & standardize the predictors but not the response. Use 'center = TRUE' to only mean center variables
summary(M100Y_lm1) # N = 1677
summary(er_an0)$r.squared # N = 1166
summary(er_an1)$r.squared # N = 1033
summary(er_an2)$r.squared # N = 743


#Including other covariates
M100Y_lm2 <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = nemo_df2)

erc_an0 <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = nemo_all_errors)
erc_an1 <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = nemo_e0_5)
erc_an2 <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = nemo_e2)

plot_summs(M100Y_lm2, erc_an0, erc_an1, erc_an2, model.names = c("Original", "All errors", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()
summary(M100Y_lm2)
summary(erc_an0)$r.squared
summary(erc_an1)$r.squared
summary(erc_an2)$r.squared
```
```{r message = FALSE, warning = FALSE, echo = FALSE, eval = FALSE}
## DIAGNOSTICS ##
#V. large sample size may make some tests unreliable - graphical methods more appropraite

#Annual climate model
M100Y_lm1 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = nemo_df2)
plot(M100Y_lm1)

summ(M100Y_lm1, vifs = TRUE)
vif(M100Y_lm1)
shapiro.test(M100Y_lm1$residuals) #graphs suggest model meets assumption, significant results may be a factor of sample size
durbinWatsonTest(M100Y_lm1) #Address with more covariates or more complex models to improve fit

```


```{r message = FALSE, warning = FALSE}
##
#Winter
##

#Without covariates
Wt100Y_lm1 <- lm(DOY ~ Tmin_wt_100Y + PPT_wt_100Y, data = nemo_df2)

er_wt0 <- lm(DOY ~ Tmin_wt_100Y + PPT_wt_100Y, data = nemo_all_errors)
er_wt1 <- lm(DOY ~ Tmin_wt_100Y + PPT_wt_100Y, data = nemo_e0_5)
er_wt2 <- lm(DOY ~ Tmin_wt_100Y + PPT_wt_100Y, data = nemo_e2)

plot_summs(Wt100Y_lm1, er_wt0, er_wt1, er_wt2, model.names = c("Original", "All errors", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()
summary(Wt100Y_lm1)
summary(er_wt0)$r.squared
summary(er_wt1)$r.squared
summary(er_wt2)$r.squared

#
#With Interactions (without other covariates)
Wt100Y_lm1i <- lm(DOY ~ Tmin_wt_100Y*PPT_wt_100Y, data = nemo_df2)

er_wt0i <- lm(DOY ~ Tmin_wt_100Y*PPT_wt_100Y, data = nemo_all_errors)
er_wt1i <- lm(DOY ~ Tmin_wt_100Y*PPT_wt_100Y, data = nemo_e0_5)
er_wt2i <- lm(DOY ~ Tmin_wt_100Y*PPT_wt_100Y, data = nemo_e2)

plot_summs(Wt100Y_lm1i, er_wt0i, er_wt1i, er_wt2i, model.names = c("Original", "All errors", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()
summary(Wt100Y_lm1i)
summary(er_wt0i)#$r.squared
summary(er_wt1i)#$r.squared
summary(er_wt2i)#$r.squared


#
#With Covariates
Wt100Y_lm2 <- lm(DOY ~ Tmin_wt_100Y + PPT_wt_100Y + elev_m + long + year, data = nemo_df2)

erc_wt0 <- lm(DOY ~ Tmin_wt_100Y + PPT_wt_100Y + elev_m + long + year, data = nemo_all_errors)
erc_wt1 <- lm(DOY ~ Tmin_wt_100Y + PPT_wt_100Y + elev_m + long + year, data = nemo_e0_5)
erc_wt2 <- lm(DOY ~ Tmin_wt_100Y + PPT_wt_100Y + elev_m + long + year, data = nemo_e2)

plot_summs(Wt100Y_lm2, erc_wt0, erc_wt1, erc_wt2, model.names = c("OG", "all errors", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()
summary(Wt100Y_lm2)
summary(erc_wt0)$r.squared
summary(erc_wt1)$r.squared
summary(erc_wt2)$r.squared
```
Including finer-scale error distances in 'wt' models with interactions increases the variance and, for 0-2 and 0-5 km, makes parameter estimates non-significant.  


```{r message = FALSE, warning = FALSE}
##
#Spring
##

#Without covariates
Sp100Y_lm1 <- lm(DOY ~ Tmin_sp_100Y + PPT_sp_100Y, data = nemo_df2)

er_sp0 <- lm(DOY ~ Tmin_sp_100Y + PPT_sp_100Y, data = nemo_all_errors)
er_sp1 <- lm(DOY ~ Tmin_sp_100Y + PPT_sp_100Y, data = nemo_e0_5)
er_sp2 <- lm(DOY ~ Tmin_sp_100Y + PPT_sp_100Y, data = nemo_e2)

plot_summs(Sp100Y_lm1, er_sp0, er_sp1, er_sp2, model.names = c("Original", "All errors", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()
summary(Sp100Y_lm1)
summary(er_sp0)$r.squared
summary(er_sp1)$r.squared
summary(er_sp2)$r.squared

#
#With interactions (without other covariates)
Sp100Y_lm1i <- lm(DOY ~ Tmin_sp_100Y*PPT_sp_100Y, data = nemo_df2)

er_sp0i <- lm(DOY ~ Tmin_sp_100Y*PPT_sp_100Y, data = nemo_all_errors)
er_sp1i <- lm(DOY ~ Tmin_sp_100Y*PPT_sp_100Y, data = nemo_e0_5)
er_sp2i <- lm(DOY ~ Tmin_sp_100Y*PPT_sp_100Y, data = nemo_e2)

plot_summs(Sp100Y_lm1i, er_sp0i, er_sp1i, er_sp2i, model.names = c("Original", "All errors", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()
summary(Sp100Y_lm1i)
summary(er_sp0i)$r.squared
summary(er_sp1i)$r.squared
summary(er_sp2i)$r.squared


#
#With Covariates - interaction ns and removed
Sp100Y_lm2 <- lm(DOY ~ Tmin_sp_100Y + PPT_sp_100Y + elev_m + long + year, data = nemo_df2)

erc_sp0 <- lm(DOY ~ Tmin_sp_100Y + PPT_sp_100Y + elev_m + long + year, data = nemo_all_errors)
erc_sp1 <- lm(DOY ~ Tmin_sp_100Y + PPT_sp_100Y + elev_m + long + year, data = nemo_e0_5)
erc_sp2 <- lm(DOY ~ Tmin_sp_100Y + PPT_sp_100Y + elev_m + long + year, data = nemo_e2)

plot_summs(Sp100Y_lm2, erc_sp0, erc_sp1, erc_sp2, model.names = c("Original", "All errors", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()
summary(Sp100Y_lm2)
summary(erc_sp0)#$r.squared
summary(erc_sp1)#$r.squared
summary(erc_sp2)#$r.squared

```


##### In Summary  


Filtering out larger error_bins led to no real improvements in model $R^2$s, though of the *subsets* the 0-5 group may have slightly better $R^2$s. Based on confidence intervals, there are no significant differences in parameter estimates between all observations and data including less uncertain coordinate estimates.  


Using data from more precise error distances led to **increases in parameter estimate variation (SE)**, especially for 0-2 km.  

Lack of improvements may be due to loss of meaningful variation from records with greater uncertainty. Also, looking only at records with any error distance, there is a reduction in $R^2$ values.

Using finer error distances may actually reduce variation and obscure meaningful variable interactions!!  


In future models consider comparing all data with those with *errors from 0-5 km*?   


<br>  



## Error Distance as a covariate   

*Note*: log-transformation of `error_dist_m` seems to improve normality, may be appropriate.  

### DOY as response  

`error_bin` level sizes:  
- <2 km = 743  
- 2-5 km = 290  
- 5-10 km = 91  
- 10-15 km = 24  
- >15 km = 18  
- NA = 511  

`
```{r message = FALSE, warning = FALSE}
#hist(nemo_df2$error_dist_m)
#hist(log(nemo_df2$error_dist_m))
#Does error distance need to be transformed? Maybe....


M100Y_lm3a <- lm(DOY ~ MAT_100Y + MAP_100Y + error_dist_m, data = nemo_df2)
M100Y_lm3b <- lm(DOY ~ MAT_100Y + MAP_100Y + error_bin, data = nemo_df2)

summary(M100Y_lm3a)
summary(M100Y_lm3b)

visreg(M100Y_lm3a)
visreg(M100Y_lm3b)

plot_summs(M100Y_lm1, M100Y_lm3a, M100Y_lm3b, model.names = c("Original", "numeric", "factor/bin"), scale = TRUE) + theme_bw()



#Other predictors included
M100Y_lm4a <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year + error_dist_m, data = nemo_df2)
M100Y_lm4b <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year + error_bin, data = nemo_df2)

summary(M100Y_lm4a)
summary(M100Y_lm4b)


plot_summs(M100Y_lm2, M100Y_lm4a, M100Y_lm4b, model.names = c("Original", "numeric", "factor/bin"), scale = TRUE) + theme_bw()

#AIC Comparison - MAT/MAP
AIC(M100Y_lm1, M100Y_lm3a, M100Y_lm3b, M100Y_lm2, M100Y_lm4a, M100Y_lm4b)
```


```{r message = FALSE, warning = FALSE}
Wt100Y_lm3a <- lm(DOY ~ Tmin_wt_100Y + PPT_wt_100Y + error_dist_m, data = nemo_df2)
Wt100Y_lm3b <- lm(DOY ~ Tmin_wt_100Y + PPT_wt_100Y + error_bin, data = nemo_df2)

summary(Wt100Y_lm3a)
summary(Wt100Y_lm3b)

plot_summs(Wt100Y_lm1, Wt100Y_lm3a, Wt100Y_lm3b, model.names = c("Original", "numeric", "factor/bin"), scale = TRUE) + theme_bw()


#With Interactions
#No interactions with error dist/bin
Wt100Y_lm3ai <- lm(DOY ~ Tmin_wt_100Y*PPT_wt_100Y + error_dist_m, data = nemo_df2)
Wt100Y_lm3bi <- lm(DOY ~ Tmin_wt_100Y*PPT_wt_100Y + error_bin, data = nemo_df2)

summary(Wt100Y_lm3ai)
summary(Wt100Y_lm3bi)

plot_summs(Wt100Y_lm1i, Wt100Y_lm3ai, Wt100Y_lm3bi, model.names = c("Original", "numeric", "factor/bin"), scale = TRUE) + theme_bw()


#With other predictors
Wt100Y_lm4a <- lm(DOY ~ Tmin_wt_100Y + PPT_wt_100Y + elev_m + long + year + error_dist_m, data = nemo_df2)
Wt100Y_lm4b <- lm(DOY ~ Tmin_wt_100Y + PPT_wt_100Y + elev_m + long + year + error_bin, data = nemo_df2)

summary(Wt100Y_lm4a)
summary(Wt100Y_lm4b)

plot_summs(Wt100Y_lm2, Wt100Y_lm4a, Wt100Y_lm4b, model.names = c("Original", "numeric", "factor/bin"), scale = TRUE) + theme_bw()


#AIC Comparison - Winter
AIC(Wt100Y_lm1, Wt100Y_lm3a, Wt100Y_lm3b, Wt100Y_lm1i, Wt100Y_lm3ai, Wt100Y_lm3bi, Wt100Y_lm2, Wt100Y_lm4a, Wt100Y_lm4b)
```


```{r message = FALSE, warning = FALSE}
####
#Spring
####
Sp100Y_lm3a <- lm(DOY ~ Tmin_sp_100Y + PPT_sp_100Y + error_dist_m, data = nemo_df2)
Sp100Y_lm3b <- lm(DOY ~ Tmin_sp_100Y + PPT_sp_100Y + error_bin, data = nemo_df2)

summary(Sp100Y_lm3a)
summary(Sp100Y_lm3b)

plot_summs(Sp100Y_lm1, Sp100Y_lm3a, Sp100Y_lm3b, model.names = c("Original", "numeric", "factor/bin"), scale = TRUE) + theme_bw()


#With Interactions
Sp100Y_lm3ai <- lm(DOY ~ Tmin_sp_100Y*PPT_sp_100Y + error_dist_m, data = nemo_df2)
Sp100Y_lm3bi <- lm(DOY ~ Tmin_sp_100Y*PPT_sp_100Y + error_bin, data = nemo_df2)

summary(Sp100Y_lm3ai)
summary(Sp100Y_lm3bi)

plot_summs(Sp100Y_lm1i, Sp100Y_lm3ai, Sp100Y_lm3bi, model.names = c("Original", "numeric", "factor/bin"), scale = TRUE) + theme_bw()


#With more covariates
Sp100Y_lm4a <- lm(DOY ~ Tmin_sp_100Y + PPT_sp_100Y + elev_m + long + year + error_dist_m, data = nemo_df2)
Sp100Y_lm4b <- lm(DOY ~ Tmin_sp_100Y + PPT_sp_100Y + elev_m + long + year + error_bin, data = nemo_df2)

summary(Sp100Y_lm4a)
summary(Sp100Y_lm4b)


plot_summs(Sp100Y_lm2, Sp100Y_lm4a, Sp100Y_lm4b, model.names = c("Original", "numeric", "factor/bin"), scale = TRUE) + theme_bw()


#AIC Comparison - Spring
AIC(Sp100Y_lm1, Sp100Y_lm3a, Sp100Y_lm3b, Sp100Y_lm1i, Sp100Y_lm3ai, Sp100Y_lm3bi, Sp100Y_lm2, Sp100Y_lm4a, Sp100Y_lm4b)


```

At a glance, $R^2$ values do not seem to be significantly improved. However, among models with error as a covariate, the factor error_bin provides a higher $R^2$ (Though estimate standard errors are huge). There appears to be no significant change in parameter estimates, similar to the results of subsetting models by different error bins.  

Is there any benefit to including error distance as a covariate in these models? Possibly in the case of milking higher $R^2$ values. See Excel sheet of model outputs for comparison. In the case of model selection via AIC, models with the `error_bin` factor had lower AIC values (lower than models without any error covariate).  

In models with `error_bin`, the 2-5 km bin had, on multiple occasions, a significant effect on DOY. (Note: Double check on whether to use `options(contrasts = c("contr.sum", "contr.poly"))` - results in different estimates among factor levels) This is explored more below in the ANOVAs.  

<br>  



### Other variables as a response - checking for error distance~geography/climate trends/biases  

#### ANOVAs and Linear Regressions    


Are there differences in collected records lat/long, elevation, MAT/MAP (other climate) due to error distance (bins)?  

Latitude & Longitude  
```{r warning = FALSE, message = FALSE}
library(car)
###Fix contrasts?
#
#Log-transformation attempted on regression models 

#Lat
#ANOVA
edbin1 <- lm(lat ~ error_bin, data = nemo_df2)
anova(edbin1)

#Regression
edbin1a <- lm(lat ~ error_dist_m, data = nemo_df2)
summary(edbin1a)


#Long
#ANOVA
edbin2 <- lm(long ~ error_bin, data = nemo_df2)
anova(edbin2)

#Regression
edbin2a <- lm(long ~ error_dist_m, data = nemo_df2)
summary(edbin2a)

```


Elevation
```{r warning = FALSE, message = FALSE}
#ANOVA
edbin3 <- lm(elev_m ~ error_bin, data = nemo_df2)
anova(edbin3)
summary(edbin3)
#Elevation not quite normally distributed - what to do? #Maybe a sqrt transformation? or glm? Or leave as is

#plots
plot(TukeyHSD(aov(edbin3)))

visreg(edbin3)
#ggplot(data = nemo_df2, aes(x = error_bin, y = elev_m)) +
#  geom_boxplot()



#Regression 
edbin3a <- lm(elev_m ~ log(error_dist_m), data = nemo_df2)
summary(edbin3a)
#marginally significant with log()

ggplot(data = nemo_df2, aes(x = log(error_dist_m), y = elev_m)) +
  geom_point() +
  geom_smooth(method = 'lm')
```


MAT
```{r warning = FALSE, message = FALSE}
#ANOVA
edbin4 <- lm(MAT_100Y ~ error_bin, data = nemo_df2)
anova(edbin4)
summary(edbin4)

plot(TukeyHSD(aov(edbin4)))
#Diff b/w 10.15-15 km and 10.15-5-10 km 
#Differences may not be significant from 0 in their effect ?

visreg(edbin4)

#No discernible trend


#Regression
edbin4a <- lm(MAT_100Y ~ error_dist_m, data = nemo_df2)
summary(edbin4a) #ns #log trnsfrm no effect
```

MAP
```{r warning = FALSE, message = FALSE}
#
#MAP 
edbin5 <- lm(MAP_100Y ~ error_bin, data = nemo_df2)
anova(edbin5)
summary(edbin5)

visreg(edbin5)

#Regression
edbin5a <- lm(MAP_100Y ~ error_dist_m, data = nemo_df2)
summary(edbin5a) #unusual - very significant

visreg(edbin5a)

edbin5b <- lm(MAP_100Y ~ log(error_dist_m), data = nemo_df2)
summary(edbin5b) #significance lost with log transformation - likely noise?

visreg(edbin5b)

```


Any variation among error_bin levels appears to be due to chance/noise, as confidence intervals are very wide and there is no main (numeric) effect of error_dist_m on any of the above response variables.   

<br>  


----  


### Investigating the effect of manually georeferenced specimens on the relationship b/w DOY and climate variables  

#### Subsetting models  

```{r message = FALSE, warning = FALSE}
#USE pre 1901 records for this? or no...
#Records we georeferenced:
nemo_geor <- nemo_df2 %>% 
  filter(!is.na(georef_by)) #N = 438 obs

nemo_ngeo <- nemo_df2 %>% 
  filter(is.na(georef_by)) #records that we did not georeference (N = 1239)

```


MAT & MAP

```{r message = FALSE, warning = FALSE}
#Our georeferenced records relative to all records
#Just climate predictors
M100Y_lmg1 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = nemo_geor)
summary(M100Y_lmg1)

#Other predictors
M100Y_lmg2 <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = nemo_geor)
summary(M100Y_lmg2)


plot_summs(M100Y_lm1, M100Y_lmg1, model.names = c("All data", "Geo"), scale = TRUE)

plot_summs(M100Y_lm2, M100Y_lmg2, model.names = c("All data", "Geo"), scale = TRUE)

```

From these averages it's clear that subsetting by specimens we georeferenced increases variation in the parameter estimate, as did subsetting by smaller error distances above. In the model with climate-only predictors, our georeferenced specimens alone may be underestimating the effect of MAT_100Y on DOY...  


What about data we did not georeference?  

```{r warning = FALSE, message = FALSE}
M100Y_lmg3<- lm(DOY ~ MAT_100Y + MAP_100Y, data = nemo_ngeo)
M100Y_lmg4<- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = nemo_ngeo)
summary(M100Y_lmg3)
summary(M100Y_lmg4)

plot_summs(M100Y_lm1, M100Y_lmg1, M100Y_lmg3, model.names = c("All data", "Geo", "Herb"), scale = TRUE)

plot_summs(M100Y_lm2, M100Y_lmg2, M100Y_lmg4, model.names = c("All data", "Geo", "Herb"), scale = TRUE)
```


Winter Conditions  
```{r warning = FALSE, message = FALSE}
#Climate-only
Wt100Y_lmg1 <- lm(DOY ~ Tmin_wt_100Y + PPT_wt_100Y, data = nemo_geor)
Wt100Y_lmg3<- lm(DOY ~ Tmin_wt_100Y + PPT_wt_100Y, data = nemo_ngeo)

#Interactions
Wt100Y_lmg1i <- lm(DOY ~ Tmin_wt_100Y*PPT_wt_100Y, data = nemo_geor)
Wt100Y_lmg3i<- lm(DOY ~ Tmin_wt_100Y*PPT_wt_100Y, data = nemo_ngeo)


#Other predictors
Wt100Y_lmg2 <- lm(DOY ~ Tmin_wt_100Y + PPT_wt_100Y + elev_m + long + year, data = nemo_geor)
Wt100Y_lmg4<- lm(DOY ~ Tmin_wt_100Y + PPT_wt_100Y + elev_m + long + year, data = nemo_ngeo)


plot_summs(Wt100Y_lm1, Wt100Y_lmg1, Wt100Y_lmg3, model.names = c("All data", "Geo", "Herb"), scale = TRUE)

plot_summs(Wt100Y_lm1i, Wt100Y_lmg1i, Wt100Y_lmg3i, model.names = c("All data", "Geo", "Herb"), scale = TRUE)

plot_summs(Wt100Y_lm2, Wt100Y_lmg2, Wt100Y_lmg4, model.names = c("All data", "Geo", "Herb"), scale = TRUE)
```


```{r warning = FALSE, message = FALSE, eval = FALSE}
summary(Wt100Y_lmg1)
summary(Wt100Y_lmg3)
summary(Wt100Y_lmg1i)
summary(Wt100Y_lmg3i)
summary(Wt100Y_lmg2)
summary(Wt100Y_lmg4)

```

Spring Conditions
```{r warning = FALSE, message = FALSE}
#Climate-only
Sp100Y_lmg1 <- lm(DOY ~ Tmin_sp_100Y + PPT_sp_100Y, data = nemo_geor)
Sp100Y_lmg3<- lm(DOY ~ Tmin_sp_100Y + PPT_sp_100Y, data = nemo_ngeo)

#Interactions
Sp100Y_lmg1i <- lm(DOY ~ Tmin_sp_100Y*PPT_sp_100Y, data = nemo_geor)
Sp100Y_lmg3i<- lm(DOY ~ Tmin_sp_100Y*PPT_sp_100Y, data = nemo_ngeo)


#Other predictors
Sp100Y_lmg2 <- lm(DOY ~ Tmin_sp_100Y + PPT_sp_100Y + elev_m + long + year, data = nemo_geor)
Sp100Y_lmg4<- lm(DOY ~ Tmin_sp_100Y + PPT_sp_100Y + elev_m + long + year, data = nemo_ngeo)


plot_summs(Sp100Y_lm1, Sp100Y_lmg1, Sp100Y_lmg3, model.names = c("All data", "Geo", "Herb"), scale = TRUE)

plot_summs(Sp100Y_lm1i, Sp100Y_lmg1i, Sp100Y_lmg3i, model.names = c("All data", "Geo", "Herb"), scale = TRUE)

plot_summs(Sp100Y_lm2, Sp100Y_lmg2, Sp100Y_lmg4, model.names = c("All data", "Geo", "Herb"), scale = TRUE)
```


```{r warning = FALSE, message = FALSE, eval = FALSE}
summary(Sp100Y_lmg1)
summary(Sp100Y_lmg3)
summary(Sp100Y_lmg1i)
summary(Sp100Y_lmg3i)
summary(Sp100Y_lmg2)
summary(Sp100Y_lmg4)

```

Ours still seem a little more variable (and NS in a couple cases), but are quite similar to herbarium-georeferenced data. It looks like our manually referenced specimens produce a **smaller sensitivity to long-term temperature**, but this becomes non-significant when geography is accounted for. Most likely due to a smaller sample size of records we georeferenced, though we may have been less accurate than others.  


```{r warning = FALSE, message = FALSE,}
#Georef_by as a covariate  
nemo_gby <- nemo_df2 %>% 
  mutate(geo_f = as_factor(case_when(!is.na(georef_by) ~ "y",
                           is.na(georef_by) ~ "n")))

M100Y_lmg3b <- lm(DOY ~ MAT_100Y + MAP_100Y + geo_f, data = nemo_gby)
M100Y_lmg4b <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year + geo_f, data = nemo_gby)

summary(M100Y_lmg3b)
visreg(M100Y_lmg3b)
summary(M100Y_lmg4b)
visreg(M100Y_lmg4b)

#Interactions
M100Y_lmg3bi <- lm(DOY ~ MAT_100Y + MAP_100Y + geo_f + geo_f:MAT_100Y, data = nemo_gby)
#M100Y_lmg4bi <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year + geo_f + geo_f:MAT_100Y, data = nemo_gby) #No interaction here

summary(M100Y_lmg3bi)
visreg(M100Y_lmg3bi)
```


Appears that, as in above analyses, some aspect of georeference source (specimens we used GEOLocate to get coords for) results in a lower parameter estimate for temperature variables. 



Other potential biases due to georeferencer  
```{r warning = FALSE, message = FALSE,}
#DOY
geo_lmg <- lm(DOY ~ geo_f, data = nemo_gby)
anova(geo_lmg)

#lat/long
geo_lmg1a <- lm(long ~ geo_f, data = nemo_gby)
geo_lmg1b <- lm(lat ~ geo_f, data = nemo_gby)
anova(geo_lmg1a)
anova(geo_lmg1b)
visreg(geo_lmg1a) #wild pattern
visreg(geo_lmg1b)

#year
geo_lmg2 <- lm(year ~ geo_f, data = nemo_gby)
anova(geo_lmg2)
visreg(geo_lmg2)

#Elev_m
geo_lmg3 <- lm(elev_m ~ geo_f, data = nemo_gby)
anova(geo_lmg3)
visreg(geo_lmg3)

#MAT
geo_lmg4 <- lm(MAT_100Y ~ geo_f, data = nemo_gby)
anova(geo_lmg4)
visreg(geo_lmg4)

#MAP
geo_lmg5 <- lm(MAP_100Y ~ geo_f, data = nemo_gby)
anova(geo_lmg5)
visreg(geo_lmg5)


#Similar pattern as with subsetting - significant effect when only-climate predictors, disappears when geographical predictors added
```

Significant differences in georeferencer source *suggests*:  

- DOY earlier for geo_f = "y"  
- Geographic biasd in non-georeferenced records (lat, long, elev_m)  
- Year earlier for specimens we georeferenced  
- Elevation lower for specimens we georeferenced  
- MAT/temp cooler for geo_f = "y"  


These geographic differences are enlightening! Help explain why it appears that temperature may differ between groups of georeferenced specimens.  


### Other potential sources of noise aside from error distance or georeferenced location?  

------  


<br>  


## Investigating Collection Bias on the relatinoship between climate and DOY  


#### Year  
Are there certain years or period with significantly higher collections? Has collections increased or decreased through time?  

```{r warning = FALSE, message = FALSE}

cb_lm1 <- lm(DOY ~ year, data = nemo_df2)
summary(cb_lm1)


#Correlate YoC with DOY collection to look for temporal collecting trend (as in Panchen 2019)

year_cor <- cor(nemo_df2 %>% select(DOY, year))
year_cor
#No correlation b/w DOY and year

```

No significant effect of year on DOY.  

```{r warning = FALSE, message = FALSE, echo = FALSE, results = 'hide'}
#Recall the distribution of DOY

ggplot(aes(x = DOY), data = nemo_df2) +
  geom_histogram(fill = "blue", color = "black") + 
  scale_y_continuous(expand = c(0,0)) + 
  theme_classic()
```


```{r warning = FALSE, message = FALSE}
#Number of specimens in each year - ID periods of low and high collection
ggplot(aes(x = year), data = nemo_df2) +
  geom_bar(stat = 'count', width = 1, fill = "blue", color = "black") +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(limits = c(1900, 2020)) +
  theme_classic()


#Parse by decade?

```


```{r warning = FALSE, message = FALSE, echo = FALSE, results = 'hide'}
# Month  
#Certain months preferred for collections? Check lat/long/elevation interactions  

cb_lm2 <- lm(DOY ~ month, data = nemo_df2)
summary(cb_lm2)
visreg(cb_lm2)


#No interacting effects. Not particularly surprising how strongly correlated DOY is to month...
nemo_df2_sz <- nemo_df2 %>% 
  mutate(M_window = case_when(month == "2" | month == "3" ~ "FM",
                              month == "4" | month == "5" ~ "AM",
                              month == "6" | month == "7" ~ "JJ")) #only a few NAs
cb_lm2a <- lm(DOY ~ M_window, data = nemo_df2_sz)
summary(cb_lm2a)


#Collection month over time:

cb_lm2b <- lm(month ~ year, data = nemo_df2)
summary(cb_lm2b)

cb_lm2c <- lm(!is.na(M_window) ~ year, data = nemo_df2_sz, na.action = na.omit)
summary(cb_lm2c)

#No shift in collection month (or period) over time

```

 


#### Location  
Are certain parts of the species range sampled more heavily (e.g. Southeast)? Across years?
Lat  
Long  


```{r warning = FALSE, message = FALSE, echo = FALSE}
library(corrplot)

corrplot(cor(nemo_df2 %>% select(lat, long, year, elev_m, DOY)))
#Use correlations to inform models ran
#No apparent effect of variables on year or vice versa

cb_lmy1a <- lm(long ~ year + lat, data = nemo_df2)
summary(cb_lmy1a) #No interactions present
visreg(cb_lmy1a)

cb_lmy1b <- lm(lat ~ year + long, data = nemo_df2)
summary(cb_lmy1b) #No interactions present, year ns
visreg(cb_lmy1b)

cb_lmy2a <- lm(elev_m ~ year, data = nemo_df2)
summary(cb_lmy2a)
visreg(cb_lmy2a)


cb_lmy2b <- lm(elev_m ~ year + long, data = nemo_df2)
summary(cb_lmy2b) #no interaction
visreg(cb_lmy2b)

```

Over time, there appears to be relatively more collections made at more inland longitudes and at higher elevations. This could be do to greater collection efforts and greater accessibility to areas in more recent decades.  




*Option*:  
Spatial Collection Patterns (Panchen 2019)  
- calculate density of specimens per [2500 m x 2500 m pixel]using `geosphere` package [or .25deg x .25deg - Daru 2018, sp package]  
- model relationship of density and distance to community (raster package)
- [test for spatial autocorrelation to detect a temporal*spatial trend]  





DOY as a response

```{r warning = FALSE, message = FALSE, echo = FALSE}
#Lat/long
cb_lm3a <- lm(DOY ~ lat, data = nemo_df2)
summary(cb_lm3a)
visreg(cb_lm3a)

cb_lm3b <- lm(DOY ~ long, data = nemo_df2)
summary(cb_lm3b)
visreg(cb_lm3b)

cb_lm4 <- lm(DOY ~ elev_m, data = nemo_df2)
summary(cb_lm4)
visreg(cb_lm4)


```


Multiple Variables:  
(Copied from 'EDA2.Rmd')  
```{r message = FALSE, warning = FALSE, echo = FALSE}
cbl_lm1 <- lm(DOY ~ elev_m + long + year, data = nemo_df1) #all years - similar to df2
cbl_lm1a <- lm(DOY ~ elev_m + long + year, data = nemo_df2) #>1900
summary(cbl_lm1a)
visreg(cbl_lm1a)



#Interactions
cbl_lm2a <- lm(DOY ~ elev_m + year*long*lat, data = nemo_df2)  
summary(cbl_lm2a) #No interactions w elevation
visreg(cbl_lm2a)

interact_plot(cbl_lm2a, pred = "year", modx = "long", mod2 = "lat") #probably better? accounts for elev_m


cbl_lm2b <- lm(DOY ~ year*long*lat, data = nemo_df2)  
summary(cbl_lm2b) #No interactions w elevation
visreg(cbl_lm2b)

interact_plot(cbl_lm2b, pred = "year", modx = "long", mod2 = "lat") 


cbl_lm2c <- lm(DOY ~ elev_m + year*long, data = nemo_df2)  
summary(cbl_lm2c) #no year:long interaction


#No two-way interactions with year


#Check VIFs?
```






#### Collector Bias  

Are there super-collectors who've collected a relatively large proportion of specimens?  
First name listed = primary collector (as in *Panchen 2019*)
- Sort primary collectors by # specimens collected. Top collectors = those who collected XX% (e.g. 90%) of all specimens  
- calculate % of collectors top collectors represent  
- (over time: correlate top collectors mean # collections per year ~ collectors' mean year of collecting)  
- (Mean DOY of top collectors - is it normally distributed? shapiro-wilks test. ID temporal biases)  

**or**  
[Via Daru 2018 - multi-spp study..]  
- Calculate # specimens for each collector  
- Is this skewed toward few collectors?  

```{r message = FALSE, warning = FALSE, echo = FALSE}
#Narrow down collector column to primary collectors
#Use nemo df1 - collections from all years

#1 - limit to first name - all characters before comma, ; , & 'and'
#Match whole words (last names only), everything before , or ;
nemo_df1_coll <- nemo_df1 %>% 
  mutate(collector_p1 = str_extract(collector, pattern = "[A-Za-z]+(?=(,|;|$))")) %>% 
  select(collector, collector_p1, everything())
  #Best method so far for extracting last names, not perfect - Would be better if there was a way to keep the initials? A few single collectors with ,/; only have first names. Last names seem pretty unique, though 2-3 Smiths & Bakers are lumped together

#works okay, only one name, sometimes first mutate(collector_p1 = str_extract(collector, pattern = "\\w+[[:space]]*[^[/., | /.;]]+")  
#Works okay mutate(collector_p1 = str_extract(collector, pattern = "[A-Z][a-z]{2,}"))

#Alternative: use similarity threshold? Would have to match initials/first letters of names and entire last names...

```


```{r message = FALSE, warning = FALSE, echo = FALSE}
coll_sums <- nemo_df1_coll %>% 
  select(collector_p1) %>% 
  group_by(collector_p1) %>% 
  summarize("Count" = n(), "Percent" = (100*n()/1764)) %>% 
  arrange(-Percent) %>% 
  mutate(top_col = case_when(Percent >= 1 ~ "y",
                             Percent < 1 ~ "n"))


head(coll_sums)
#Highest individual collection percent does not exceed 2.5% (2.6237% in nemo_df2)

#Assign top collectors as those who collected > 1% ##Is this too small?


#What percent of all collectors are top collectors?
100*count(coll_sums %>% filter(top_col == "y"))/count(coll_sums)

#Approx. 2.22%
```

Top collector contributions are very unlikely to have any meaningful bias on the data due to their very small sample sizes.  

```{r message = FALSE, warning = FALSE, echo = FALSE}
se <- function(x){
  sd(x)/sqrt(length(x))
}
#Investigate potential biases
#DOY
#Filter df to top collectors
nemo_df1_coll_top <- nemo_df1_coll %>% 
  filter(collector_p1 %in% c("Sanders", "Gander", "Swinney", "Munz", "Tracy", "Rebman", "Helmkamp", "Jepson", "Smith", "Boyd", "Chandler", "Wheeler", "Constance", "White", "Baker"))


ggplot(aes(x = DOY), data = nemo_df1_coll_top) +
  geom_histogram(fill = "blue", color = "black") + 
  scale_y_continuous(expand = c(0,0)) + 
  theme_classic() +
  facet_wrap(~collector_p1)

#Does not appear to be any bias in DOY due to collector!


#Check top collectors mean # of collections per year, and mean year of collections

coll_sums2 <- nemo_df1_coll_top %>% 
  select(collector_p1, DOY, year) %>% 
  group_by(collector_p1) %>% 
  summarize("Count" = n(), "Percent" = (100*n()/1764), "Year_M" = mean(year), "Year_SE" = se(year), "Year_Range" = paste(min(year),",", max(year)), "DOY_M" = mean(DOY), "DOY_SE" = se(DOY)) %>% #Smith & Baker will be erroneous - lumped collectors
  arrange(-Percent) 
  
head(coll_sums2)

sum(coll_sums2$Count) #Top collectors contributed 382 specimens
```


Compare subsetted data (or with collector as covariate) to og data in pheno-climatic models?  
Not sure this makes sense, top collectors contributed a large number of records
```{r message = FALSE, warning = FALSE, echo = FALSE}
nemo_df1_notop <- nemo_df1_coll %>% 
  filter(!collector_p1 %in% c("Sanders", "Gander", "Swinney", "Munz", "Tracy", "Rebman", "Helmkamp", "Jepson", "Smith", "Boyd", "Chandler", "Wheeler", "Constance", "White", "Baker"))

collb_lm1 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = nemo_df1_coll) #Base data, with collector_p
collb_lm2 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = nemo_df1_notop)

summary(collb_lm1)
summary(collb_lm2)

plot_summs(collb_lm1, collb_lm2, model.names = c("Original", "No top collectors"), scale = TRUE)

```




#### Phenological stage [when PI scoring complete]  
Are certain phenophases (e.g. peak flowering) over-represented?  
(Are plants preferrentially collected during peak flowering) (Biases against v. early or late-stage phenophases)











