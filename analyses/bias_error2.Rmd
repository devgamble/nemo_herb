---
title: "bias_error2"
author: "Devin Gamble"
date: "8/24/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Additional analyses on the effect of coordinate uncertainty (error distance) on pheno-climatic models  

*TO-DO*  
- Increase Bootstrap Rs  
- Evaluate resampling from full models (all covariates)  

```{r echo = FALSE, message = FALSE, warning = FALSE}
#Load Packages
library(car)
library(tidyverse)
library(here)
library(ggplot2)
library(visreg)
library(jtools)
library(interactions)
library(kableExtra)
library(stringr)
library(microbenchmark) #measure run times
```


#### Load Data  
```{r message = FALSE, warning = FALSE}
nemo_df2 <- read_csv(here::here("data_cleaning", "nemo_full_1901_2019.csv")) %>%  
  mutate(error_bin = as_factor(error_bin)) #Should this be ordered? #Combined specimen & climate data from 1901-2019
#1677 obs, 1251 columns

nemo_df1 <- read_csv(here::here("data_cleaning", "nemo_full_1861_2019.csv")) #Combined data for all years
#1764 obs, 1251 columns

options(contrasts = c("contr.sum", "contr.poly"))
```

Data subset by error distances/bins  
```{r message = FALSE, warning = FALSE}
#All errors
nemo_all_errors <- nemo_df2 %>% 
  filter(!is.na(error_dist_m)) 
#1239 out of 1764 obs with error distance
#1166 after rm records before 1901

#0-5 km resolution
nemo_e0_5 <- nemo_all_errors %>% 
  filter(error_bin == "<2 km" | error_bin == "2-5 km") 

#0-4 km - not used here
nemo_e0_4 <-  nemo_all_errors %>% 
  filter(error_dist_m >= 0 & error_dist_m <= 4000) #Do Not include error_bin in models

#0-2 km
nemo_e2 <- nemo_all_errors %>% 
  filter(error_bin == "<2 km") 

```

Smallest sample size is N = 743 in 0-2 km data subset. Randomly sample 743 obs from each subset and compare models.  
<br>  


#### Early conceptual analyses - Not Evaluated  
**MAT & MAP**  
```{r warning = FALSE, message = FALSE, eval = FALSE, fig.show='hide'}
#####
# Full Data
#####

#Set seed for consistency?
#set.seed(407)

#Only MAT & MAP
#Sample 1
M100Y_sub1 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = sample_n(nemo_df2, size = 743, replace = FALSE))
#Sample 2
M100Y_sub2 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = sample_n(nemo_df2, size = 743, replace = FALSE))
#Sample 3
M100Y_sub3 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = sample_n(nemo_df2, size = 743, replace = FALSE))
#Sample 4
M100Y_sub4 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = sample_n(nemo_df2, size = 743, replace = FALSE))
#Sample 5
M100Y_sub5 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = sample_n(nemo_df2, size = 743, replace = FALSE))

plot_summs(M100Y_sub1, M100Y_sub2, M100Y_sub3, M100Y_sub4, M100Y_sub5, model.names = c("og1", "og2", "og3", "og4", "og5"), scale = TRUE) + theme_bw()

#all_obs_MATMAP_models <- list(M100Y_sub1, M100Y_sub2, M100Y_sub3, M100Y_sub4, M100Y_sub5) #Cannot extract models for 

#With other geography & year
#Sample 1
M100Y_sub1c <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = sample_n(nemo_df2, size = 743, replace = FALSE))
#Sample 2
M100Y_sub2c <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = sample_n(nemo_df2, size = 743, replace = FALSE))
#Sample 3
M100Y_sub3c <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = sample_n(nemo_df2, size = 743, replace = FALSE))
#Sample 4
M100Y_sub4c <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = sample_n(nemo_df2, size = 743, replace = FALSE))
#Sample 5
M100Y_sub5c <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = sample_n(nemo_df2, size = 743, replace = FALSE))

plot_summs(M100Y_sub1c, M100Y_sub2c, M100Y_sub3c, M100Y_sub4c, M100Y_sub5c, model.names = c("og1", "og2", "og3", "og4", "og5"), scale = TRUE) + theme_bw()


#####
# All Errors  
#####

#Only MAT & MAP
#Sample 1
M100Y_sube1 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = sample_n(nemo_all_errors, size = 743, replace = FALSE))
#Sample 2
M100Y_sube2 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = sample_n(nemo_all_errors, size = 743, replace = FALSE))
#Sample 3
M100Y_sube3 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = sample_n(nemo_all_errors, size = 743, replace = FALSE))
#Sample 4
M100Y_sube4 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = sample_n(nemo_all_errors, size = 743, replace = FALSE))
#Sample 5
M100Y_sube5 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = sample_n(nemo_all_errors, size = 743, replace = FALSE))

plot_summs(M100Y_sube1, M100Y_sube2, M100Y_sube3, M100Y_sube4, M100Y_sube5, model.names = c("all_e1", "all_e2", "all_e3", "all_e4", "all_e5"), scale = TRUE) + theme_bw()

#With other geography & year
#Sample 1
M100Y_sube1c <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = sample_n(nemo_all_errors, size = 743, replace = FALSE))
#Sample 2
M100Y_sube2c <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = sample_n(nemo_all_errors, size = 743, replace = FALSE))
#Sample 3
M100Y_sube3c <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = sample_n(nemo_all_errors, size = 743, replace = FALSE))
#Sample 4
M100Y_sube4c <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = sample_n(nemo_all_errors, size = 743, replace = FALSE))
#Sample 5
M100Y_sube5c <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = sample_n(nemo_all_errors, size = 743, replace = FALSE))

plot_summs(M100Y_sube1c, M100Y_sube2c, M100Y_sube3c, M100Y_sube4c, M100Y_sube5c, model.names = c("all_e1", "all_e2", "all_e3", "all_e4", "all_e5"), scale = TRUE) + theme_bw()


#####
# 0-5 km Error  
#####

#Only MAT & MAP
#Sample 1
M100Y_sube51 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = sample_n(nemo_e0_5, size = 743, replace = FALSE))
#Sample 2
M100Y_sube52 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = sample_n(nemo_e0_5, size = 743, replace = FALSE))
#Sample 3
M100Y_sube53 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = sample_n(nemo_e0_5, size = 743, replace = FALSE))
#Sample 4
M100Y_sube54 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = sample_n(nemo_e0_5, size = 743, replace = FALSE))
#Sample 5
M100Y_sube55 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = sample_n(nemo_e0_5, size = 743, replace = FALSE))

plot_summs(M100Y_sube51, M100Y_sube52, M100Y_sube53, M100Y_sube54, M100Y_sube55, model.names = c("0-5_1", "0-5_2", "0-5_3", "0-5_4", "0-5_5"), scale = TRUE) + theme_bw()

#With other geography & year
#Sample 1
M100Y_sube51c <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = sample_n(nemo_e0_5, size = 743, replace = FALSE))
#Sample 2
M100Y_sube52c <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = sample_n(nemo_e0_5, size = 743, replace = FALSE))
#Sample 3
M100Y_sube53c <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = sample_n(nemo_e0_5, size = 743, replace = FALSE))
#Sample 4
M100Y_sube54c <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = sample_n(nemo_e0_5, size = 743, replace = FALSE))
#Sample 5
M100Y_sube55c <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = sample_n(nemo_e0_5, size = 743, replace = FALSE))

plot_summs(M100Y_sube51c, M100Y_sube52c, M100Y_sube53c, M100Y_sube54c, M100Y_sube55c, model.names = c("0-5_1", "0-5_2", "0-5_3", "0-5_4", "0-5_5"), scale = TRUE) + theme_bw()


#####
# 0-2 km Error  
#####
M100Y_sube21 <- lm(DOY ~ MAT_100Y + MAP_100Y, data = nemo_e2)

M100Y_sube21c <- lm(DOY ~ MAT_100Y + MAP_100Y + elev_m + long + year, data = nemo_e2)
```
```{r warning = FALSE, message = FALSE, eval = FALSE, fig.show = 'hide'}
#Compare different subsets...


plot_summs(M100Y_sub1, M100Y_sube1, M100Y_sube51, M100Y_sube21, model.names = c("OG", "All_E", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()
plot_summs(M100Y_sub2, M100Y_sube2, M100Y_sube52, M100Y_sube21, model.names = c("OG", "All_E", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()
plot_summs(M100Y_sub3, M100Y_sube3, M100Y_sube53, M100Y_sube21, model.names = c("OG", "All_E", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()
plot_summs(M100Y_sub4, M100Y_sube4, M100Y_sube54, M100Y_sube21, model.names = c("OG", "All_E", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()
plot_summs(M100Y_sub5, M100Y_sube5, M100Y_sube55, M100Y_sube21, model.names = c("OG", "All_E", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()

#All covariates
plot_summs(M100Y_sub1c, M100Y_sube1c, M100Y_sube51c, M100Y_sube21c, model.names = c("OG", "All_E", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()
plot_summs(M100Y_sub2c, M100Y_sube2c, M100Y_sube52c, M100Y_sube21c, model.names = c("OG", "All_E", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()
plot_summs(M100Y_sub3c, M100Y_sube3c, M100Y_sube53c, M100Y_sube21c, model.names = c("OG", "All_E", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()
plot_summs(M100Y_sub4c, M100Y_sube4c, M100Y_sube54c, M100Y_sube21c, model.names = c("OG", "All_E", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()
plot_summs(M100Y_sub5c, M100Y_sube5c, M100Y_sube55c, M100Y_sube21c, model.names = c("OG", "All_E", "0-5 km", "0-2 km"), scale = TRUE) + theme_bw()
```
<br>  



## Bootstrap Resampling Analysis  

*Bins*  
- Original Data set  
- Error Distance present  
- 0-5 km error  
- 0-2 km error  

**Objective**  
1. Re-sample from the three larger data sets (OG, All errors, 0-5 km) at N = 743 (size of 0-2 km)  
2. For each resample, fit a pheno-climatic linear model (for each data set)  
3. Compare the parameter estimates (for climate variables) and confidence intervals based on xxxx samples  
4. Compute significance of differences between estimates among each data set  



#### Early by-hand attempt
```{r message = FALSE, eval = FALSE}
# Attempt first with one data set

samplelm_params <- matrix(data = NA, nrow = 100, ncol = 8)
colnames(samplelm_params) <-  c("MAT_est", "MAP_est", "MAT_SE", "MAP_SE", "MAT_Clo", "MAT_Cup", "MAP_Cup", "MAP_Clo")


for(i in 1:100){
  #sample
  sample_og <- sample_n(nemo_df2, size = 743, replace = FALSE)

  #modeling
  lm_n <- lm(DOY ~ MAT_100Y + MAP_100Y, data = sample_og)
    
  #store coeffs, std.e [row, col]
  coeffs <- summary(lm_n)$coefficients[c(2:3),1] #2:3 to exclude intercept, inc MAT & MAP
  stde <- summary(lm_n)$coefficients[c(2:3),2]
  
  samplelm_params[i,] <- as.numeric(c(coeffs, stde, 
                            as.numeric(confint(object = lm_n, parm = 'MAT_100Y', level = 0.95)), 
                            as.numeric(confint(object = lm_n, parm = 'MAP_100Y', level = 0.95)))) #Calculate CIs. Must specify vars
  
} 
#for 1:1000, takes about a minute

####
# Significance Tests

# Are parameter estimates significantly different from 0? From each other wrt different error subsets?
#How much do the fits of each sample differ? (variance?)
#Cross-validation: estimate test error? Bootstrapping?

```


*CI type: Norm or BCa (or other e.g. PERC)??*  


### Bootstrap Analysis  
#### MAT & MAP Alone

Goal: Estimate the sampling distribution of a statistic (regression coefficient). The repeated sampling provides the bootstrap mean and SE of the metric. Mimics the sampling of our data from the population. Obtain sampling distribution of the metric.  
Default method for lm regression bootstrap is random-x or case resampling. Bias estimates the bias of the statistic relative to the true population value.  

**R** = 2000 resamples  

Confidence Intervals:  
- Norm type assumes estimates are normally distributed - looks accurate from histograms (below)  
- Alternative: BCA confint method - corrects for bias/skewedness in bootstrapped distribution, uses original estimates unlike norm method  


```{r message = FALSE}
library(boot) #Alternative: try Boot() ftn from `car` package
#Option: Set seed for reproducible result
set.seed(12345)


#In boot() below, each call of the function is without replacement, but replacement = TRUE over multiple samples

#Create function to call in boot()
param_est <- function(df, index){ # df = data, index = # obs to inc [req by boot()]
  
  df_samp <- sample_n(df, size = 743, replace = FALSE) #boot() recomputes the function for each re-sample
  lm_c <- lm(DOY ~ MAT_100Y + MAP_100Y, data = df_samp)
  
  coef(lm_c)
}

#e.g. param_est(nemo_df2, 1:743)


#Save boostrapped data - all observations
boot_df2 <- boot(nemo_df2, param_est, 2000)


#Confidence Intervals
#####
# -- by hand  
#index = 2 for MAT, = 3 for MAP

#boot_df2_ci_MAT <- boot.ci(boot_df2, index = 2, conf = 0.95, type = 'norm') 
#boot_df2_ci_MAP <- boot.ci(boot_df2, index = 3, conf = 0.95, type = 'norm') #low ci is especially negative...
#Alternative: Confint method - car package
#####

boot_df2_ci <- Confint(boot_df2, level = 0.95, type = "norm") #identical to boot.ci() #above#


#Outputs
summary(boot_df2)
boot_df2_ci #confidence intervals do not include bootstrapped estimates...

#Compare to SEs in regular summary. #If SEs are similar b/w boot and original lm outputs, method is appropriate
summary(lm(DOY ~ MAT_100Y + MAP_100Y, data = nemo_df2))


#Plot
plot(boot_df2) #can specify index for different predictors (default = intercept)
hist(boot_df2, ci = 'norm', legend = "separate")

#Distribution of samples appear fairly normally distributed, though confidence intervals (horizontal black bars) are uneven. 
#Observed value of statistic = original estimate (bootMed)


boot_df2_gg <- data.frame(c(boot_df2$t0[2], boot_df2$t0[3]), boot_df2_ci[2:3, 1:2]) #save bootstrapped estimates for MAT, MAP 

boot_df2_ggp <- rownames_to_column(boot_df2_gg) %>% 
  mutate(data = "all")
colnames(boot_df2_ggp) <- c("var", "bootEst", "ci_2.5", "ci_97.5", "data")

```


```{r message = FALSE}
###
# For the subset data:
###

###
#nemo_all_errors
boot_alle <- boot(nemo_all_errors, param_est, 2000)
boot_alle_ci <- Confint(boot_alle, level = 0.95, type = "norm")

#outputs
summary(boot_alle)
boot_alle_ci

#og lm
summary(lm(DOY ~ MAT_100Y + MAP_100Y, data = nemo_all_errors))

plot(boot_alle)
hist(boot_alle, ci = 'norm', legend = "separate") #CIs look super weird... which type to use???

boot_alle_gg <- data.frame(c(boot_alle$t0[2], boot_alle$t0[3]), boot_alle_ci[2:3, 1:2])

boot_alle_ggp <- rownames_to_column(boot_alle_gg) %>% 
  mutate(data = "all_E")
colnames(boot_alle_ggp) <- c("var", "bootEst", "ci_2.5", "ci_97.5", "data")


###
#nemo_e0_5
boot_05 <- boot(nemo_e0_5, param_est, 2000)
boot_05_ci <- Confint(boot_05, level = 0.95, type = "norm")

#outputs
summary(boot_05)
boot_05_ci

#og lm
summary(lm(DOY ~ MAT_100Y + MAP_100Y, data = nemo_e0_5))

plot(boot_05)
hist(boot_05, ci = 'norm', legend = "separate") 

boot_05_gg <- data.frame(c(boot_05$t0[2], boot_05$t0[3]), boot_05_ci[2:3, 1:2])

boot_05_ggp <- rownames_to_column(boot_05_gg) %>% 
  mutate(data = "05km")
colnames(boot_05_ggp) <- c("var", "bootEst", "ci_2.5", "ci_97.5", "data")


###
#nemo_e2 - should have identical results each time #Does not make sense to bootstrap this data set.

#boot_02 <- boot(nemo_e2, param_est, 1000)
#boot.ci(boot_02, index = 2, conf = 0.95, type = 'norm')
#plot(boot_02) - Same data, no distribution of estimates.

#lm sumamry
M100Y_02_lm <- lm(DOY ~ MAT_100Y + MAP_100Y, data = nemo_e2)
summary(M100Y_02_lm) 
#SEs from bootstrap are much much smaller but estimates are identical, as expected

confint(M100Y_02_lm, level = 0.95, type = "norm")

Nboot_02_gg <- data.frame(c(summary(M100Y_02_lm)$coefficient[2], summary(M100Y_02_lm)$coefficient[3]), confint(M100Y_02_lm, level = 0.95, type = "norm")[2:3, 1:2])

Nboot_02_ggp <- rownames_to_column(Nboot_02_gg) %>% 
  mutate(data = "02km")
colnames(Nboot_02_ggp) <-  c("var", "bootEst", "ci_2.5", "ci_97.5", "data")


```


##### Plotting Coefficient Estimates with confidence intervals  
```{r message = FALSE}
##
# Comparing & Plotting bootstrapped parameter estimates
# 95% confidence intervals computed by COnfint (identical to boot.ci) using type = #### (norm)?

#Combine different subset boot estimates 

boots_alldata <- rbind(boot_df2_ggp, boot_alle_ggp, boot_05_ggp, Nboot_02_ggp) %>% 
  mutate(data = factor(data, levels = c("all", "all_E", "05km", "02km")))



ggplot(data = boots_alldata) +
  geom_errorbarh(aes(y = var, xmin = ci_2.5, xmax = ci_97.5, color = data), size = 1) +
  geom_point(aes(x = bootEst, y = var), size = 2) + 
  geom_vline(xintercept = 0, lty = 2) +
  scale_x_continuous(breaks = seq(-10, 10, 1)) +
  scale_color_brewer(palette = "Dark2") +
  facet_wrap(~data, ncol = 1) +
  theme_bw()


```


#### MAT & MAP + Other Covariates  
*Copy, paste, and refix above code*  



---  



## Randomly simulated coordinates (lat/long) by a set error distance  

How does varying point coordinates by different error distances affect pheno-climatic models?  

Steps:  
1. Assign each record (0-2 km set) four sets of new coordinates, each dispersed in a random direction from the original  
  - 2 km away  
  - 5 km away  
  - 15 km away  
  - 25 km away  
2. Obtain climate data for each new coordinate set  
3. Compare models of the original 2 km data set with those of the 4 new data sets  
4. Replication (5x)  

<br>  

Determining new coordinates based on km will depend on the present latitude and longitude of a collection. Simulations here are based off a subset of the original data for which confidence in specimen collection locations is high (0-2 km) so that deviations in the parameter estimates and $R^2$ values of models from simulated data can be attributed to effects of real differences in collection uncertainty AND locations. Use the WGS84 ellipsoid (the datum used for the majority of records; some NAD83 and NAD27 [*calculate % in 0-2km data*]) to calculate new decimal degrees based on some km deviation at each record. 

"geosphere" package -> `destPoint()` function computes a new coordinate point (WGS84) when given a start point, initial bearing, and distance.  


### Assign new coordinates  
#### SIMULTATIONS ONLY for HIGH-CONFIDENCE COLLECTIONS (0-2 KM ERROR DISTANCE)  

```{r}
library(geosphere)
nemo_r_2 <- nemo_e2 %>% 
  select(specimen_number:mature_5)

#destPoint from geosphere package - e.g.
destPoint(p = c(-120.0312, 37.47905), b = 45, d = 2000) #default WGS84
#Seems pretty accurate!!! (Compared start and end points in Google maps)


##
### Goal: apply destPoint() to all existing lat/long to get new lat/long, each with *different* random bearing

#Basic for loop
  long_n1 <- rep(NA, nrow(nemo_r_2))
  lat_n1 <- rep(NA, nrow(nemo_r_2))
  
for(i in 1:length(nemo_r_2$lat)){
  
  
  latlong_n <- destPoint(p = c(nemo_r_2$long[i], nemo_r_2$lat[i]), b = sample(0:360, 1), d = 1000)
  
  long_n1[i] <-  latlong_n[1]
  lat_n1[i] <-  latlong_n[2]
   
}


#######
# 2 km error new coords
#######
#Simulations + for loop

  
sim_list_2ka <- list()

for(x in 1:10){ #10 reps
  
  long_n1 <- rep(NA,nrow(nemo_r_2))
  lat_n1 <- rep(NA, nrow(nemo_r_2))

  
for(i in 1:length(nemo_r_2$lat)){
  
  latlong_n <- destPoint(p = c(nemo_r_2$long[i], nemo_r_2$lat[i]), b = sample(0:360, 1), d = runif(1, 0, 2000))
  
  long_n1[i] <-  latlong_n[1]
  lat_n1[i] <-  latlong_n[2]
   
}
  
  sim_list_2ka[[x]] <- cbind(nemo_r_2$specimen_number, long_n1, lat_n1)
  colnames(sim_list_2ka[[x]]) <- c("specimen_number", "long_n2k", "lat_n2k")
  
  print(x)
  
}
  
  
#Rbind all list elements

  
#Using bind_rows()
#sims_all_2ka <- bind_rows(sim_list_2ka[[1:10]])


#using reduce() 
sims_all_2ka <- as.data.frame(reduce(sim_list_2ka, rbind)) %>% 
  mutate(replicate = c(rep("rep1", times = 743), rep("rep2", times = 743), rep("rep3", times = 743), rep("rep4", times = 743),rep("rep5", times = 743),rep("rep6", times = 743),rep("rep7", times = 743), rep("rep8", times = 743), rep("rep9", times = 743), rep("rep10", times = 743))) %>% 
  mutate(long_n2k = as.numeric(long_n2k), lat_n2k = as.numeric(lat_n2k))
```

##### Add elevation to records (optional for ClimateNA)  
**Very time-consuming!!!**  
```{r message = FALSE, eval = FALSE}
#Add elevation
library(elevatr)
prj_dd <- "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs" #Define parameters for get_elev_point()


sims_all_2kaE <- get_elev_point(sims_all_2ka[,2:3], prj = prj_dd, src = "epqs")

  
#Standardized csv for ClimateNA...
#Combine multiple datasets into single long csv for ClimateNA data retrieval? Maybe have ID2 = replicate identifier...


  
```


```{r eval = FALSE, message = FALSE}
#DEFUNCT/FAILED ANALYSES
library(elevatr) #must have package rgdal installed!
#Get elevation for new coords as well
prj_dd <- "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs" #Define parameters for get_elev_point()

for(x in 1:length(sim_list_2ka)){
  
elev_n1 <- rep(NA, nrow(nemo_r_2))

for(i in 1:length(nemo_r_2$lat)){

elev_n1[i] <- get_elev_point(as.numeric(sim_list_2ka[[x]][,2:3]), prj = prj_dd, src = "epqs")

  
}

sim_list_2ka_e[[x]] <- cbind(sim_list_2ka, elev_n1)

}

######Unable to apply for loop using get_elev_point to list - too complicated




#Tadeo's randCoord function
#randCoord(x = c(-120.66, -120), y = c(34.66, 37), d_min = 1.5, d_max = 2.5)

#randCoord(x = nemo_r_2$long, y = nemo_r_2$lat, d_min = 1.5, d_max = 2.5)


# apply() functions approach


#destPoint alone
nemo_ncoords_2km <- nemo_r_2 %>% 
  mutate(long_n1 = sapply(X = c(long, lat), FUN = destPoint(long, lat, b = sample(0:360, 1), d = 2000)))


#getLatLong_r function
nemo_ncoords_2km <- nemo_r_2 %>% 
  mutate(longlat_n1 = sapply(X = c(long, lat, d = 2000), FUN = getLatLong_r(lat = lat, long = long)))

#destPoint(p = c(long, lat), b = sample(0:360, 1), d = 2000)[,1]) #for loop or tapply

nemo_ncoords_2km <- nemo_r_2 %>% 
  mutate(long_n1 = NA, lat_n1 = NA)



```








## SUBSET by 0-2km (highest certainty records) to simulate randomized coordinates

```{r}

```

